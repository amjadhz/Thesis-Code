{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d21c4939",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ICU Admission Prediction: Multi-Model Comparison with SMOTE\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, RocCurveDisplay\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from xgboost import XGBClassifier\n",
    "from pygam import LogisticGAM, s\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import matplotlib.pyplot as plt\n",
    "import shap\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"prepared_clinical_dataset.csv\")\n",
    "\n",
    "# Define features and target\n",
    "X = df.drop(columns=[\"ICU_Admission\"])\n",
    "y = df[\"ICU_Admission\"]\n",
    "\n",
    "# Scale features for models that are sensitive to scale\n",
    "scaler = StandardScaler()\n",
    "X_scaled = pd.DataFrame(scaler.fit_transform(X), columns=X.columns)\n",
    "\n",
    "# Apply SMOTE to address class imbalance\n",
    "smote = SMOTE(random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(X_scaled, y)\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, stratify=y_resampled, random_state=42)\n",
    "\n",
    "# Container for model evaluation results\n",
    "results = {}\n",
    "\n",
    "# 1. Logistic Regression\n",
    "lr = LogisticRegression(max_iter=1000)\n",
    "lr.fit(X_train, y_train)\n",
    "y_pred_lr = lr.predict(X_test)\n",
    "results['Logistic Regression'] = classification_report(y_test, y_pred_lr, output_dict=True)\n",
    "\n",
    "# 2. Decision Tree\n",
    "tree = DecisionTreeClassifier(max_depth=4, random_state=42)\n",
    "tree.fit(X_train, y_train)\n",
    "y_pred_tree = tree.predict(X_test)\n",
    "results['Decision Tree'] = classification_report(y_test, y_pred_tree, output_dict=True)\n",
    "\n",
    "# 3. Naive Bayes\n",
    "gnb = GaussianNB()\n",
    "gnb.fit(X_train, y_train)\n",
    "y_pred_nb = gnb.predict(X_test)\n",
    "results['Naive Bayes'] = classification_report(y_test, y_pred_nb, output_dict=True)\n",
    "\n",
    "# 4. Generalized Additive Model (GAM)\n",
    "gam = LogisticGAM(s(0) + s(1) + s(2)).fit(X_train.values, y_train.values)  # Adjust s() for features\n",
    "pred_proba_gam = gam.predict_proba(X_test.values)\n",
    "y_pred_gam_class = (pred_proba_gam > 0.5).astype(int)\n",
    "results['GAM'] = classification_report(y_test, y_pred_gam_class, output_dict=True)\n",
    "\n",
    "# 5. XGBoost\n",
    "xgb = XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n",
    "xgb.fit(X_train, y_train)\n",
    "y_pred_xgb = xgb.predict(X_test)\n",
    "results['XGBoost'] = classification_report(y_test, y_pred_xgb, output_dict=True)\n",
    "\n",
    "# Evaluation summary\n",
    "for model_name, report in results.items():\n",
    "    print(f\"\\n=== {model_name} ===\")\n",
    "    print(pd.DataFrame(report).T)\n",
    "\n",
    "# ROC Curve for all models\n",
    "plt.figure(figsize=(10, 6))\n",
    "for name, model in zip([\n",
    "    'Logistic Regression', 'Decision Tree', 'Naive Bayes', 'GAM', 'XGBoost'\n",
    "], [lr, tree, gnb, gam, xgb]):\n",
    "    if name == 'GAM':\n",
    "        y_score = gam.predict_proba(X_test.values)\n",
    "    else:\n",
    "        y_score = model.predict_proba(X_test)[:, 1]\n",
    "    RocCurveDisplay.from_predictions(y_test, y_score, name=name)\n",
    "plt.title(\"ROC Curves\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "# Feature importance (Tree and XGBoost)\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.barh(X.columns, tree.feature_importances_)\n",
    "plt.title(\"Decision Tree Feature Importance\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.barh(X.columns, xgb.feature_importances_)\n",
    "plt.title(\"XGBoost Feature Importance\")\n",
    "plt.show()\n",
    "\n",
    "# SHAP values for XGBoost\n",
    "explainer = shap.Explainer(xgb)\n",
    "shap_values = explainer(X_test)\n",
    "shap.summary_plot(shap_values, X_test, plot_type=\"bar\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
